{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(fileName: str):\n",
    "    \"\"\" Read the .csv file and combine all data into a large dataset\n",
    "\n",
    "    Read .csv file from current folder, put all records into dataframe, and \n",
    "    return the dataset and labels.\n",
    "\n",
    "    Arg:\n",
    "        fileName(str): The string that contain the .csv file location.\n",
    "\n",
    "    Return:\n",
    "        A dataframe that contain all record from .csv file.\n",
    "        The labels for all features.\n",
    "\n",
    "    Rasies:\n",
    "        File Error: File not exist or not in the correct location.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(fileName)\n",
    "        # dataset = df.drop(['action', 'object', 'location'], axis=1)\n",
    "        # df['text'] = (df.content).apply(clean_text)\n",
    "        # dataset = df.drop(['tweet_id', 'sentiment', 'content'], axis=1)\n",
    "        # labels = df.drop(['tweet_id', 'content', 'text'], axis=1)\n",
    "        dataset = df['transcription']\n",
    "        labels = df['action']\n",
    "        return dataset, labels\n",
    "    except:\n",
    "        print(\"Open file error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/toygarr/mixup-text-augmentation-in-emotion-detection-task\n",
    "    \"\"\"\n",
    "    regex_html = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    remove_digits = str.maketrans('', '', string.digits + string.punctuation)\n",
    "    text = re.sub(regex_html, '', text)\n",
    "    text = text.translate(remove_digits)\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).split()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheng\\Documents\\Machine Learning\\MLCodes\\MLAssignments\\Assignment03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                        Turn on the kitchen lights\n",
       "1                           Turn up the temperature\n",
       "2        OK now switch the main language to Chinese\n",
       "3                Turn down the bathroom temperature\n",
       "4                               Change the language\n",
       "                            ...                    \n",
       "11561                               Kitchen heat up\n",
       "11562                       Turn the temperature up\n",
       "11563                                   Bring shoes\n",
       "11564                                   Volume mute\n",
       "11565                   Turn off the kitchen lights\n",
       "Name: transcription, Length: 11566, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = os.path.abspath('.')\n",
    "print(dirPath)\n",
    "# fileName = \"tweet_emotions.csv\"\n",
    "fileName = dirPath + \"\\\\train_data.csv\"\n",
    "dataset, labels = readCSV(fileName)\n",
    "# X = dataset['text']\n",
    "X = dataset\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "# y = label_encoder.fit_transform(labels['sentiment'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11566, 65)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learning the vocabulary dictionary and return document-term matrix\n",
    "c_vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "text_dt_matrix = c_vectorizer.fit_transform(X)\n",
    "text_dt_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning the vocabulary dictionary and return document-term matrix\n",
    "# sen_dt_matrix = c_vectorizer.fit_transform(labels['sentiment'])\n",
    "# sen_dt_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'turn': 60,\n",
       " 'kitchen': 22,\n",
       " 'lights': 28,\n",
       " 'temperature': 59,\n",
       " 'ok': 40,\n",
       " 'switch': 58,\n",
       " 'main': 33,\n",
       " 'language': 25,\n",
       " 'chinese': 6,\n",
       " 'bathroom': 2,\n",
       " 'change': 5,\n",
       " 'sound': 55,\n",
       " 'decrease': 9,\n",
       " 'heating': 18,\n",
       " 'washroom': 64,\n",
       " 'loud': 29,\n",
       " 'bedroom': 3,\n",
       " 'heat': 17,\n",
       " 'increase': 20,\n",
       " 'set': 50,\n",
       " 'need': 38,\n",
       " 'practice': 45,\n",
       " 'english': 12,\n",
       " 'hear': 16,\n",
       " 'volume': 63,\n",
       " 'lamp': 24,\n",
       " 'bring': 4,\n",
       " 'shoes': 52,\n",
       " 'newspaper': 39,\n",
       " 'fetch': 14,\n",
       " 'socks': 53,\n",
       " 'make': 34,\n",
       " 'music': 36,\n",
       " 'louder': 30,\n",
       " 'phone': 43,\n",
       " 'lower': 32,\n",
       " 'korean': 23,\n",
       " 'far': 13,\n",
       " 'max': 35,\n",
       " 'juice': 21,\n",
       " 'device': 10,\n",
       " 'video': 62,\n",
       " 'low': 31,\n",
       " 'play': 44,\n",
       " 'audio': 1,\n",
       " 'quieter': 47,\n",
       " 'languages': 26,\n",
       " 'quiet': 46,\n",
       " 'resume': 49,\n",
       " 'use': 61,\n",
       " 'different': 11,\n",
       " 'mute': 37,\n",
       " 'hotter': 19,\n",
       " 'pause': 42,\n",
       " 'levels': 27,\n",
       " 'german': 15,\n",
       " 'start': 56,\n",
       " 'settings': 51,\n",
       " 'stop': 57,\n",
       " 'softer': 54,\n",
       " 'reduce': 48,\n",
       " 'allow': 0,\n",
       " 'couldn': 8,\n",
       " 'cooler': 7,\n",
       " 'open': 41}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = c_vectorizer.vocabulary_\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['allow', 'audio', 'bathroom', 'bedroom', 'bring', 'change',\n",
       "       'chinese', 'cooler', 'couldn', 'decrease', 'device', 'different',\n",
       "       'english', 'far', 'fetch', 'german', 'hear', 'heat', 'heating',\n",
       "       'hotter', 'increase', 'juice', 'kitchen', 'korean', 'lamp',\n",
       "       'language', 'languages', 'levels', 'lights', 'loud', 'louder',\n",
       "       'low', 'lower', 'main', 'make', 'max', 'music', 'mute', 'need',\n",
       "       'newspaper', 'ok', 'open', 'pause', 'phone', 'play', 'practice',\n",
       "       'quiet', 'quieter', 'reduce', 'resume', 'set', 'settings', 'shoes',\n",
       "       'socks', 'softer', 'sound', 'start', 'stop', 'switch',\n",
       "       'temperature', 'turn', 'use', 'video', 'volume', 'washroom'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10551    Turn up the temperature in the kitchen\n",
       "6339                           Turn the lamp on\n",
       "6068                                       Play\n",
       "9280            Could you increase the heating?\n",
       "2748                          Kitchen lights on\n",
       "                          ...                  \n",
       "4859                            Bedroom heat up\n",
       "919                   Lights off in the kitchen\n",
       "500                        Go get the newspaper\n",
       "4517                Turn on the bathroom lights\n",
       "5925                          Bedroom lights on\n",
       "Name: transcription, Length: 8674, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "v_mnb_model = Pipeline(steps=[('vectorizer', c_vectorizer), ('classifier', mnb_model)])\n",
    "v_mnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7576071922544951"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_mnb_model.fit(X_train, y_train)\n",
    "v_mnb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"Cj get ac os\"]\n",
    "predictions = v_mnb_model.predict(text)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcdafa320b1bd52415b4da26a3e91d8c55e0b68a992d8fe533e9215398eb0247"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
